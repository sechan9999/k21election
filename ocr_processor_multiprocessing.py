#!/usr/bin/env python3
"""
ë©€í‹°í”„ë¡œì„¸ì‹± ê¸°ë°˜ ëŒ€ìš©ëŸ‰ ì„ ê±° ê°œí‘œìƒí™©í‘œ OCR ì²˜ë¦¬ ì‹œìŠ¤í…œ
Multi-processing Korean Election Ballot OCR System for Large-scale Processing
"""

import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Tuple
from multiprocessing import Pool, cpu_count, Manager
from functools import partial
import warnings
warnings.filterwarnings('ignore')

import fitz  # PyMuPDF
import numpy as np
from PIL import Image
import cv2


class MultiProcessingOCR:
    """ë©€í‹°í”„ë¡œì„¸ì‹± OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, num_workers: int = None, gpu: bool = False):
        """
        ì´ˆê¸°í™”

        Args:
            num_workers: ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: CPU ì½”ì–´ ìˆ˜)
            gpu: GPU ì‚¬ìš© ì—¬ë¶€ (ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ ì£¼ì˜ í•„ìš”)
        """
        self.num_workers = num_workers or max(1, cpu_count() - 1)
        self.gpu = gpu

        print(f"ğŸ”§ ë©€í‹°í”„ë¡œì„¸ì‹± OCR ì´ˆê¸°í™”")
        print(f"   - ì›Œì»¤ ìˆ˜: {self.num_workers}")
        print(f"   - CPU ì½”ì–´: {cpu_count()}")
        print(f"   - GPU ì‚¬ìš©: {self.gpu}")

        # í›„ë³´ì ì •ë³´
        self.candidates = {
            1: {'name': 'ì´ì¬ëª…', 'party': 'ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹'},
            2: {'name': 'ê¹€ë¬¸ìˆ˜', 'party': 'êµ­ë¯¼ì˜í˜'},
            4: {'name': 'ì´ì¤€ì„', 'party': 'ê°œí˜ì‹ ë‹¹'},
            5: {'name': 'ê¶Œì˜êµ­', 'party': 'ë¯¼ì£¼ë…¸ë™ë‹¹'},
            8: {'name': 'ì†¡ì§„í˜¸', 'party': 'ë¬´ì†Œì†'},
        }

    @staticmethod
    def extract_page_as_image(pdf_path: str, page_num: int, dpi: int = 200) -> Tuple[int, np.ndarray]:
        """
        PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œ (ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ìš©)

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (0-indexed)
            dpi: í•´ìƒë„

        Returns:
            (page_num, image_array)
        """
        doc = fitz.open(pdf_path)
        page = doc[page_num]

        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        mat = fitz.Matrix(dpi / 72, dpi / 72)
        pix = page.get_pixmap(matrix=mat)

        # numpy arrayë¡œ ë³€í™˜
        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)

        # RGB ë³€í™˜ (í•„ìš”ì‹œ)
        if pix.n == 4:  # RGBA
            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)

        doc.close()

        return page_num, img

    @staticmethod
    def preprocess_image(image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image

        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)

        # ëŒ€ë¹„ í–¥ìƒ
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)

        return enhanced

    @staticmethod
    def process_page_worker(
        args: Tuple[str, int, int, str, bool]
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬ ì›Œì»¤ í•¨ìˆ˜ (ë©€í‹°í”„ë¡œì„¸ì‹±ìš©)

        Args:
            args: (pdf_path, page_num, dpi, output_dir, use_ocr)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        pdf_path, page_num, dpi, output_dir, use_ocr = args

        start_time = time.time()

        try:
            # ì´ë¯¸ì§€ ì¶”ì¶œ
            _, image = MultiProcessingOCR.extract_page_as_image(pdf_path, page_num, dpi)

            # ì „ì²˜ë¦¬
            processed = MultiProcessingOCR.preprocess_image(image)

            # OCR ìˆ˜í–‰ (ì„ íƒì )
            ocr_result = None
            if use_ocr:
                try:
                    # EasyOCR ì´ˆê¸°í™” (ê° í”„ë¡œì„¸ìŠ¤ë³„)
                    import easyocr
                    reader = easyocr.Reader(['ko', 'en'], gpu=False)  # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ GPU ë¹„í™œì„±í™”
                    ocr_result = reader.readtext(processed)
                except ImportError:
                    ocr_result = None
                    print(f"âš ï¸  í˜ì´ì§€ {page_num + 1}: EasyOCR ë¯¸ì„¤ì¹˜ë¨")

            # ê²°ê³¼ ì €ì¥
            result = {
                'page_number': page_num + 1,
                'success': True,
                'image_shape': image.shape,
                'processing_time': time.time() - start_time,
                'has_ocr': ocr_result is not None,
                'ocr_text_count': len(ocr_result) if ocr_result else 0
            }

            # OCR ê²°ê³¼ ì €ì¥ (ìˆì„ ê²½ìš°)
            if ocr_result:
                result['ocr_results'] = [
                    {
                        'text': text,
                        'confidence': float(conf),
                        'bbox': bbox
                    }
                    for bbox, text, conf in ocr_result
                ]
                result['avg_confidence'] = np.mean([r[2] for r in ocr_result]) if ocr_result else 0.0

            # ì´ë¯¸ì§€ ì €ì¥
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
                img_path = os.path.join(output_dir, f'page_{page_num + 1:04d}.png')
                cv2.imwrite(img_path, processed)
                result['image_path'] = img_path

            # JSON ì €ì¥
            if output_dir:
                json_path = os.path.join(output_dir, f'page_{page_num + 1:04d}.json')
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)

            return result

        except Exception as e:
            return {
                'page_number': page_num + 1,
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }

    def process_pdf_parallel(
        self,
        pdf_path: str,
        output_dir: str = './ocr_results_mp',
        dpi: int = 200,
        first_page: int = None,
        last_page: int = None,
        use_ocr: bool = True,
        chunk_size: int = 10
    ) -> List[Dict[str, Any]]:
        """
        PDFë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            dpi: í•´ìƒë„
            first_page: ì‹œì‘ í˜ì´ì§€ (1-indexed)
            last_page: ë í˜ì´ì§€ (1-indexed)
            use_ocr: OCR ìˆ˜í–‰ ì—¬ë¶€
            chunk_size: ì²­í¬ í¬ê¸° (í•œë²ˆì— ì²˜ë¦¬í•  í˜ì´ì§€ ìˆ˜)

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # PDF ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        doc.close()

        # í˜ì´ì§€ ë²”ìœ„ ì„¤ì •
        start_idx = (first_page - 1) if first_page else 0
        end_idx = last_page if last_page else total_pages
        page_range = range(start_idx, end_idx)

        print(f"\nğŸ“„ PDF ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
        print(f"   íŒŒì¼: {pdf_path}")
        print(f"   ì´ í˜ì´ì§€: {total_pages}")
        print(f"   ì²˜ë¦¬ ë²”ìœ„: {start_idx + 1} ~ {end_idx}")
        print(f"   ì›Œì»¤ ìˆ˜: {self.num_workers}")
        print(f"   DPI: {dpi}")
        print(f"   OCR ì‚¬ìš©: {use_ocr}")

        # ì‘ì—… ì¸ì ì¤€ë¹„
        tasks = [
            (pdf_path, page_num, dpi, output_dir, use_ocr)
            for page_num in page_range
        ]

        # ë©€í‹°í”„ë¡œì„¸ì‹± í’€ë¡œ ì²˜ë¦¬
        results = []
        start_time = time.time()

        with Pool(processes=self.num_workers) as pool:
            # imapìœ¼ë¡œ ì§„í–‰ìƒí™© í‘œì‹œ
            for i, result in enumerate(pool.imap(self.process_page_worker, tasks, chunksize=chunk_size), 1):
                results.append(result)

                # ì§„í–‰ìƒí™© ì¶œë ¥
                if result['success']:
                    print(f"   âœ“ [{i}/{len(tasks)}] í˜ì´ì§€ {result['page_number']}: "
                          f"{result['processing_time']:.2f}ì´ˆ", end='')
                    if result.get('has_ocr'):
                        print(f" (OCR: {result['ocr_text_count']}ê°œ)", end='')
                    print()
                else:
                    print(f"   âœ— [{i}/{len(tasks)}] í˜ì´ì§€ {result['page_number']}: "
                          f"ì‹¤íŒ¨ - {result.get('error', 'Unknown error')}")

        # í†µí•© ê²°ê³¼ ì €ì¥
        total_time = time.time() - start_time
        summary = {
            'pdf_path': pdf_path,
            'total_pages': total_pages,
            'processed_pages': len(results),
            'successful_pages': sum(1 for r in results if r['success']),
            'failed_pages': sum(1 for r in results if not r['success']),
            'total_processing_time': total_time,
            'average_time_per_page': total_time / len(results) if results else 0,
            'num_workers': self.num_workers,
            'results': results
        }

        # í†µí•© JSON ì €ì¥
        os.makedirs(output_dir, exist_ok=True)
        summary_path = os.path.join(output_dir, 'processing_summary.json')
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*60}")
        print(f"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"ì„±ê³µ: {summary['successful_pages']}/{summary['processed_pages']}í˜ì´ì§€")
        print(f"í‰ê·  ì²˜ë¦¬ ì†ë„: {summary['average_time_per_page']:.2f}ì´ˆ/í˜ì´ì§€")
        print(f"ì˜ˆìƒ 126í˜ì´ì§€ ì²˜ë¦¬ ì‹œê°„: {summary['average_time_per_page'] * 126 / 60:.1f}ë¶„")
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥: {output_dir}")
        print(f"   - ìš”ì•½: {summary_path}")
        print(f"   - ì´ë¯¸ì§€: {summary['successful_pages']}ê°œ PNG íŒŒì¼")
        print(f"   - ë°ì´í„°: {summary['successful_pages']}ê°œ JSON íŒŒì¼")

        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description='ë©€í‹°í”„ë¡œì„¸ì‹± ê¸°ë°˜ ì„ ê±° ê°œí‘œìƒí™©í‘œ OCR ì²˜ë¦¬'
    )
    parser.add_argument(
        'pdf_path',
        type=str,
        help='ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default='./ocr_results_mp',
        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ./ocr_results_mp)'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=None,
        help='ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: CPU ì½”ì–´ ìˆ˜ - 1)'
    )
    parser.add_argument(
        '--first-page',
        type=int,
        default=None,
        help='ì‹œì‘ í˜ì´ì§€ (1-indexed)'
    )
    parser.add_argument(
        '--last-page',
        type=int,
        default=None,
        help='ë í˜ì´ì§€ (1-indexed)'
    )
    parser.add_argument(
        '--dpi',
        type=int,
        default=200,
        help='ì´ë¯¸ì§€ í•´ìƒë„ (ê¸°ë³¸ê°’: 200)'
    )
    parser.add_argument(
        '--no-ocr',
        action='store_true',
        help='OCR ë¹„í™œì„±í™” (ì´ë¯¸ì§€ ì¶”ì¶œë§Œ)'
    )
    parser.add_argument(
        '--chunk-size',
        type=int,
        default=10,
        help='ì²­í¬ í¬ê¸° (ê¸°ë³¸ê°’: 10)'
    )

    args = parser.parse_args()

    # ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = MultiProcessingOCR(num_workers=args.workers)

    # PDF ì²˜ë¦¬
    results = processor.process_pdf_parallel(
        pdf_path=args.pdf_path,
        output_dir=args.output_dir,
        dpi=args.dpi,
        first_page=args.first_page,
        last_page=args.last_page,
        use_ocr=not args.no_ocr,
        chunk_size=args.chunk_size
    )

    print(f"\nğŸ‰ ì™„ë£Œ: {len(results)}ê°œ í˜ì´ì§€ ì²˜ë¦¬ë¨")


if __name__ == '__main__':
    main()
